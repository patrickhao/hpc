{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed for deferring annotation parsing in TVMScript\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import relax as R\n",
    "from tvm.script import tir as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import fx\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import te\n",
    "A = te.placeholder((128, 128), name=\"A\", dtype=\"float32\")\n",
    "B = te.placeholder((128, 128), name=\"B\", dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.te.tensor.Tensor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128, 128]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过一系列张量表达式来描述计算。这里的`te.compute`使用`te.compute(output_shape, fcompute)`这样的接口。fcompute函数描述了我们要如何计算给定索引的每个元素[i, j]的值。\n",
    "\n",
    "`te_matmul`函数接受一个`te.Tensor`类型的对象，并返回矩阵乘法结果。请注意我们是如何根据A和B的输入shape构造计算的。`te_matmul`适用于具有不同输入shape的A和B。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def te_matmul(A: te.Tensor, B: te.Tensor) -> te.Tensor:\n",
    "    assert A.shape[1] == B.shape[0]\n",
    "    n = A.shape[0]\n",
    "    m = B.shape[1]\n",
    "    k = te.reduce_axis((0, A.shape[1]), name=\"k\")\n",
    "    return te.compute((n, m), lambda i, j: te.sum(A[i, k] * B[k, j], axis=k), name=\"matmul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = te_matmul(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">func</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "    <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "    <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
       "            i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, i2])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[i, k], B[k, j])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[i, j])\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "            matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[k, j]\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "te.create_prim_func([A, B, C]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是一个适用于任何维度的Relu函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu\n",
    "def te_relu(A: te.Tensor) -> te.Tensor:\n",
    "    # 允许任何形状的输入\n",
    "    return te.compute(A.shape, lambda *i: te.max(A(*i), 0), name=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面尝试不同纬度和shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">func</span>(X1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[<span style=\"color: #008000\">10</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>], relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[<span style=\"color: #008000\">10</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "    <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "    <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i0 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>serial(<span style=\"color: #008000\">10</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "            i0_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">10</span>, i0)\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(X1[i0_1])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[i0_1])\n",
       "            relu[i0_1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(X1[i0_1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X1 = te.placeholder((10,), name=\"X1\", dtype=\"float32\")\n",
    "Y1 = te_relu(X1)\n",
    "te.create_prim_func([X1, Y1]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">func</span>(X1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "    <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "    <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "            i0_1, i1_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(X1[i0_1, i1_1])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[i0_1, i1_1])\n",
       "            relu[i0_1, i1_1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(X1[i0_1, i1_1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X2 = te.placeholder((10, 20), name=\"X1\", dtype=\"float32\")\n",
    "Y2 = te_relu(X2)\n",
    "te.create_prim_func([X2, Y2]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "te API允许我们做的另一件事是组合操作并创建“融合(fused)”算子。例如，我们可以将matmul的结果再次应用relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = te_matmul(A, B)\n",
    "D = te_relu(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过只传递感兴趣的输入和输出值，跳过中间值来创建一个 TensorIR 函数。 这将导致 matmul 的结果被分配为 TensorIR 函数中的临时空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">func</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "    <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "    <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "    matmul <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer([<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
       "            i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, i2])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[i, k], B[k, j])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[i, j])\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "            matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[k, j]\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "            i0_1, i1_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(matmul[i0_1, i1_1])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[i0_1, i1_1])\n",
       "            relu[i0_1, i1_1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(matmul[i0_1, i1_1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "te.create_prim_func([A, B, D]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还可以将中间结果C传递到参数列表中。在这种情况下，TensorIR函数希望我们也从调用方传入C。通常我们**建议只传入输入和输出**，这样我们就可以在里面进行更高级的融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">func</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "    <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "    <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
       "            i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, i2])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[i, k], B[k, j])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[i, j])\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "            matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[k, j]\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "            i0_1, i1_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(matmul[i0_1, i1_1])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[i0_1, i1_1])\n",
       "            relu[i0_1, i1_1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(matmul[i0_1, i1_1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 在外面把C的内存开好传进去\n",
    "te.create_prim_func([A, B, C, D]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于多个TensorIR函数，通过计算图进行连接，首先创建一个`block builder`，借助它来帮助我们逐步构建一个`relax.Function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">te_matmul</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;te_matmul&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
       "                i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, i2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[i, k], rxplaceholder_1[k, j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[i, j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[k, j]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">te_relu</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;te_relu&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "                i0_1, i1_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[i0_1, i1_1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[i0_1, i1_1])\n",
       "                relu[i0_1, i1_1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[i0_1, i1_1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">main</span>(A: Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #008000\">2</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_matmul, (A, B), (<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_relu, (lv,), (<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            gv: Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv1\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = relax.Var(\"A\", (128, 128), relax.DynTensorType(2, \"float32\"))\n",
    "B = relax.Var(\"B\", (128, 128), relax.DynTensorType(2, \"float32\"))\n",
    "\n",
    "bb = relax.BlockBuilder()\n",
    "\n",
    "with bb.function(\"main\"):\n",
    "  with bb.dataflow():\n",
    "    C = bb.emit_te(te_matmul, A, B)\n",
    "    D = bb.emit_te(te_relu, C)\n",
    "    R = bb.emit_output(D)\n",
    "  bb.emit_func_output(R, params=[A, B])\n",
    "\n",
    "MyModule = bb.get()\n",
    "MyModule.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BlockBuilder带有与Relax函数中相应的作用域。例如，`bb.dataflow()`创建一个dataflow block，其中所有对BlockBuilder的调用都处在dataflow block的作用域中，每个中间结果都是`relax.Var`，对应一个存储计算结构的变量，DataflowVar表示该变量是dataflow block和计算图内的中间步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relax.expr.DataflowVar"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(C, relax.Var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb.emit_te`做了如下的事情\n",
    "+ 为A和B创建一个输入`te.placeholder`\n",
    "+ 通过`te_matmul`函数运行它们\n",
    "+ 调用`te.create_prim_func`来创建一个TensorIR函数\n",
    "+ 通过`call_tir`生成对函数的调用\n",
    "可以通过`bb.emit_output`创建每个dataflow block的输出变量，即可以在dataflow block之外引用的变量\n",
    "\n",
    "最后，函数输出由`bb.emit_func_output`标记。 我们只能在每个函数作用域内调用一次emit_func_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大多数机器学习框架都带有计算图抽象，其中**每个节点对应一个操作，边对应它们之间的依赖关系**。我们将采用PyTorch模型，获取PyTorch原生格式的计算图，并将其转换为IRModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 继承nn.Module\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.weight = nn.Parameter(torch.randn(128, 128))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.matmul(x, self.weight)\n",
    "    x = torch.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面使用TorchFx来表示来自PyTorch的模型的计算图，并将其转化为IRModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.fx.graph_module.GraphModule.__new__.<locals>.GraphModuleImpl"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "\n",
    "fx_module = fx.symbolic_trace(model)\n",
    "type(fx_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                     args         kwargs\n",
      "-------------  ------  ---------------------------------------------------------  -----------  --------\n",
      "placeholder    x       x                                                          ()           {}\n",
      "get_attr       weight  weight                                                     ()           {}\n",
      "call_function  matmul  <built-in method matmul of type object at 0x7fae1ada1b20>  (x, weight)  {}\n",
      "call_function  relu    <built-in method relu of type object at 0x7fae1ada1b20>    (matmul,)    {}\n",
      "output         output  output                                                     (relu,)      {}\n"
     ]
    }
   ],
   "source": [
    "fx_module.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于PyTorch来说，weight本身是已知的，不是未知的输入（X），其中可能包含一些优化的空间，需要分开标注"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整体的翻译逻辑流程如下\n",
    "+ 创建一个node_map，将`fx.Node`映射到相应的`relax.Var`，该`relax.Var`代表IRModule中已翻译的节点\n",
    "+ 以拓扑顺序迭代FX图中的节点\n",
    "+ 给定映射输入，获取节点的映射输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_param(param: nn.Parameter):\n",
    "    ndim = len(param.data.shape)\n",
    "    return relax.const(\n",
    "        param.data.cpu().numpy(), relax.DynTensorType(ndim, \"float32\")\n",
    "    )\n",
    "\n",
    "def fetch_attr(fx_mod, target: str):\n",
    "    \"\"\"Helper function to fetch an attr\"\"\"\n",
    "    target_atoms = target.split('.')\n",
    "    attr_itr = fx_mod\n",
    "    for i, atom in enumerate(target_atoms):\n",
    "        if not hasattr(attr_itr, atom):\n",
    "            raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "        attr_itr = getattr(attr_itr, atom)\n",
    "    return attr_itr\n",
    "\n",
    "# 给定fx module，将其转化为IR Module\n",
    "def from_fx(fx_mod, input_shapes, call_function_map, call_module_map):\n",
    "    input_index = 0\n",
    "    node_map = {}\n",
    "    named_modules = dict(fx_mod.named_modules())\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "\n",
    "    fn_inputs = []\n",
    "    fn_output = None\n",
    "    with bb.function(\"main\"):\n",
    "        with bb.dataflow():\n",
    "            # 这个列表已经进行好拓扑排序\n",
    "            for node in fx_mod.graph.nodes:\n",
    "                if node.op == \"placeholder\":\n",
    "                    # create input placeholder\n",
    "                    shape = input_shapes[input_index]\n",
    "                    input_index += 1\n",
    "                    input_var = relax.Var(\n",
    "                        node.target, shape, relax.DynTensorType(len(shape), \"float32\")\n",
    "                    )\n",
    "                    fn_inputs.append(input_var)\n",
    "                    node_map[node] = input_var\n",
    "                elif node.op == \"get_attr\":\n",
    "                    node_map[node] = map_param(fetch_attr(fx_mod, node.target))\n",
    "                elif node.op == \"call_function\":\n",
    "                    node_map[node] = call_function_map[node.target](bb, node_map, node)\n",
    "                elif node.op == \"call_module\":\n",
    "                    named_module = named_modules[node.target]\n",
    "                    node_map[node] = call_module_map[type(named_module)](bb, node_map, node, named_module)\n",
    "                elif node.op == \"output\":\n",
    "                    output = node_map[node.args[0]]\n",
    "                    assert fn_output is None\n",
    "                    fn_output = bb.emit_output(output)\n",
    "        # output and finalize the function\n",
    "        bb.emit_func_output(output, fn_inputs)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面没有在from_fx函数中定义函数映射，通过映射提供每个torch function的翻译规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">te_matmul</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;te_matmul&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
       "                i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, i2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[i, k], rxplaceholder_1[k, j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[i, j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[k, j]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">te_relu</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;te_relu&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "                i0_1, i1_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[i0_1, i1_1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[i0_1, i1_1])\n",
       "                relu[i0_1, i1_1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[i0_1, i1_1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">main</span>(x: Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #008000\">2</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_matmul, (x, meta[relay<span style=\"color: #AA22FF; font-weight: bold\">.</span>Constant][<span style=\"color: #008000\">0</span>]), (<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_relu, (lv,), (<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            gv: Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv1\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> lv1\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_matmul(bb, node_map, node: fx.Node):\n",
    "    A = node_map[node.args[0]]\n",
    "    B = node_map[node.args[1]]\n",
    "    return bb.emit_te(te_matmul, A, B)\n",
    "\n",
    "def map_relu(bb, node_map, node: fx.Node):\n",
    "    A = node_map[node.args[0]]\n",
    "    return bb.emit_te(te_relu, A)\n",
    "\n",
    "MyModule = from_fx(\n",
    "    fx_module,\n",
    "    input_shapes = [(1, 128)],\n",
    "    call_function_map = {\n",
    "      torch.matmul: map_matmul,\n",
    "      torch.relu: map_relu,\n",
    "    },\n",
    "    call_module_map={},\n",
    ")\n",
    "\n",
    "MyModule.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "img, label = next(iter(test_loader))\n",
    "img = img.reshape(1, 28, 28).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAGiCAYAAADHpO4FAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAziklEQVR4nO3dfXRU9b3v8c/MJJkkkARDyBNEnrRS5cmCpKkPxWMOAbtoqZx1EL2CLIpXm7iELKvSCvHpmBaPlGMb5dYWadcSRbt8OFUXLpoavF5Bl7E5Hu6tURBLFBKehEAgM8nMvn9QRkcSyG/PJLM383659lqys7/z+2VnJ9/5/fZv9tdjWZYlAADgWN5EdwAAAJwZyRoAAIcjWQMA4HAkawAAHI5kDQCAw5GsAQBwOJI1AAAOR7IGAMDhSNYAADgcyRoAAIcjWQMAYODNN9/U7NmzVVxcLI/Ho5deeumsMQ0NDfrWt74lv9+vCy64QOvXrzdqk2QNAICBjo4OTZo0SXV1dX06fteuXfre976nq6++Wk1NTVq6dKl+9KMf6fXXX+9zmx4KeQAAYI/H49GLL76oOXPm9HrM3XffrVdffVXbt2+P7Lv++ut1+PBhbdq0qU/tpMTa0XgLh8Pas2ePsrKy5PF4Et0dAIAhy7J09OhRFRcXy+vtvwnczs5OBYPBmF/HsqzT8o3f75ff74/5tSVp69atKi8vj9pXUVGhpUuX9vk1HJes9+zZo5KSkkR3AwAQo5aWFo0YMaJfXruzs1OjRw5W675QzK81ePBgHTt2LGpfTU2N7rvvvphfW5JaW1tVUFAQta+goEDt7e06ceKEMjIyzvoajkvWWVlZkqQrdK1SlJrg3iSY12ceE479wu2rYPmlxjEt/2J+12XQdvN3t4W/fsc4Bl/a8atvGcek7TP/czLylaPGMdZf/2YcY5vDfwedqltdekuvRf6e94dgMKjWfSHtahyp7Cz7o/f2o2GNnvJ3tbS0KDs7O7I/XqPqeHFcsj41FZGiVKV4kjxZe2z8ofAM3JrBcEq6cYw3wzxZ+2z80iT9tRMjb4aNn226+Z+TFJ/5FKY1kD9bh/8OOtY/fs0H4lZmdpY3pmQdeZ3s7KhkHU+FhYVqa2uL2tfW1qbs7Ow+jaqlflwNXldXp1GjRik9PV2lpaV69913+6spAECSClnhmLf+VlZWpvr6+qh9mzdvVllZWZ9fo1+S9caNG1VdXa2amhq9//77mjRpkioqKrRv377+aA4AkKTCsmLeTB07dkxNTU1qamqSdPKjWU1NTdq9e7ckafny5VqwYEHk+FtvvVWffPKJ7rrrLn344Yd6/PHH9dxzz2nZsmV9brNfkvXq1au1ZMkSLVq0SBdffLHWrl2rzMxMrVu37rRjA4GA2tvbozYAAPoiHIf/TL333nu69NJLdemlJ9ftVFdX69JLL9XKlSslSXv37o0kbkkaPXq0Xn31VW3evFmTJk3So48+qt/+9reqqKjoc5txv2cdDAbV2Nio5cuXR/Z5vV6Vl5dr69atpx1fW1ur+++/P97dAACgX0yfPl1nekRJT08nmz59uv7617/abjPuI+sDBw4oFAr1uEy9tbX1tOOXL1+uI0eORLaWlpZ4dwkAcI4KWVbMmxskfDV4PD94DgBILnbvO3813g3iPrLOy8uTz+frcZl6YWFhvJsDAOCcF/dknZaWpilTpkQtUw+Hw6qvrzdapg4AwNmEZSkUw+aWkXW/TINXV1dr4cKFmjp1qqZNm6Y1a9aoo6NDixYt6o/mAABJKlmmwfslWc+bN0/79+/XypUr1draqsmTJ2vTpk2nLTrDWdh4bGH7/G8bx4T+x0HjGEk62Gzj8jlm/otxfOpx45jWO75jHCNJw/6r0zjG1/C+rbZMecePM44Z9uQeW23t+nvAOCZ02Px6aF4yyDhGlVONQy5+cL95O5K6d/3dVhwQb/22wKyqqkpVVVX99fIAAMS8opvV4AAA9LPwP7ZY4t2AJ84DAOBwjKwBAK51alV3LPFuQLIGALhWyDq5xRLvBiRrAIBrcc8aAAA4AiNrAIBrheVRSJ6Y4t2AZA0AcK2wdXKLJd4NmAYHAMDhGFkDAFwrFOM0eCyxA4lkDQBwLZI1euXx+41jrIB5YYTAtZcZx2iBecGCI4355u1ISg2ZX+TeLvN2wvnmBU1OFNq7EdWanm4cs31Dk3HM/w2eMI751/9lXpxk9x6fcYwkdbdlGsf4j5pfDynHzf8EdWWZf9jm//3U3jX+jf/5mXmQjQI88tr4OdlpB65FsgYAuFbY8ihsxbAaPIbYgUSyBgC4VrJMg7MaHAAAh2NkDQBwrZC8CsUw7nTLnX+SNQDAtawY71lb3LMGAKB/cc8aAAA4AiNrAIBrhSyvQlYM96xd8mxwkjUAwLXC8igcwyRxWO7I1kyDAwDgcIysAQCulSwLzEjWAADXiv2eNdPgAAAgDhhZ22B1dQ9IO7v/1by6kLX3POOYFLtXQYr5O9KM/eZTTocPZRjHpI7uMI6RJN/WwcYxF627zTjGGzQ/D9055ufbF7L3fjzrE/O4YI55O8Eh5td4qo3qXp4RncYxktQ+z7zyXfYz24xjPKnmv4RWwC3P3upfJxeYxVDIg2lwAAD6VzjGx42yGhwAAMQFI2sAgGslywIzkjUAwLXC8ibFQ1FI1gAA1wpZHoViqJwVS+xA4p41AAAOx8gaAOBaoRhXg4eYBgcAoH+FLa/CMSwwC7tkgRnT4AAAOBwjawCAazENDgCAw4UV24pu8wfeJgbT4AAAOBwjazvCA/MA/cFDjhvHHD00yDgmlGFvGijluPm72Y7h5m2d918+45hj3zUOkSTlzf7MOOb474qNYzqKzM/dN8t3GMf87c8XGsdIUjjVPMYy/zHZuobsCBzz24r7Ypz5eCbbRjsDVRzoXBT7Q1HcMWYlWQMAXCv2x426I1m7o5cAACQxRtYAANeinjUAAA6XLNPgJGsAgGvF/jlrdyRrd/QSAIAkxsgaAOBaYcujcCwPRXFJiUySNQDAtcIxToO75XPW7uglAABJjJE1AMC1Yi+R6Y4xK8kaAOBaIXkUiuGz0rHEDiR3vKUAACCJMbJ2sGDQ/MfjSzcvCBA+bqMCg6Rwivk7Uv8h85gTw4xDNHiLeUETSdpVal7BYmZ1k3HMoWCmccx/vT7OOCb9kHGIJKk73V6cKY+NmjjeoPk15Dlq709dcOjAFO2xVRzIa+/3dqAKEQ0UpsEBAHC4kGKbynbLWxd3vKUAACCJMbIGALhWskyDx72X9913nzweT9Q2bpz5vTYAAM7mVCGPWDY36JdeXnLJJdq7d29ke+utt/qjGQBAkrP+USLT7mbZvN9dV1enUaNGKT09XaWlpXr33XfPePyaNWt00UUXKSMjQyUlJVq2bJk6Ozv73F6/TIOnpKSosLCwT8cGAgEFAoHIv9vb2/ujSwAAxMXGjRtVXV2ttWvXqrS0VGvWrFFFRYWam5uVn59/2vEbNmzQPffco3Xr1uk73/mOPvroI918883yeDxavXp1n9rsl5H1xx9/rOLiYo0ZM0Y33nijdu/e3euxtbW1ysnJiWwlJSX90SUAwDkoEdPgq1ev1pIlS7Ro0SJdfPHFWrt2rTIzM7Vu3boej3/77bd1+eWX64YbbtCoUaM0Y8YMzZ8//6yj8a+Ke7IuLS3V+vXrtWnTJj3xxBPatWuXrrzySh09erTH45cvX64jR45EtpaWlnh3CQBwjjpVdSuWTTo5q/vV7aszvl8VDAbV2Nio8vLyyD6v16vy8nJt3bq1x5jvfOc7amxsjCTnTz75RK+99pquvfbaPn+fcZ8GnzVrVuT/J06cqNLSUo0cOVLPPfecFi9efNrxfr9ffr8/3t0AAKDPvj6rW1NTo/vuu++04w4cOKBQKKSCgoKo/QUFBfrwww97fO0bbrhBBw4c0BVXXCHLstTd3a1bb71VP/3pT/vcv37/6NaQIUP0jW98Qzt27OjvpgAASSYUY4nMU7EtLS3Kzs6O7I/nILKhoUEPP/ywHn/8cZWWlmrHjh2644479OCDD2rFihV9eo1+T9bHjh3Tzp07ddNNN/V3UwCAJPPVqWy78ZKUnZ0dlax7k5eXJ5/Pp7a2tqj9bW1tvS6sXrFihW666Sb96Ec/kiRNmDBBHR0duuWWW/Szn/1MXu/Z32zE/Z71nXfeqS1btujTTz/V22+/rR/+8Ify+XyaP39+vJsCAGBApaWlacqUKaqvr4/sC4fDqq+vV1lZWY8xx48fPy0h+3wnn+1uWVaf2o37yPqzzz7T/PnzdfDgQQ0bNkxXXHGFtm3bpmHDbFRj6G8D+CB8z5RLjGMChzKMY1KH9P1ze6eEUvp2sXxdOCNsHBPMMX9/mHbE/F2z5bP3Tjt/s3khj//z128Zx6ScMD/n2Z3mMR1FA1f+rzvTvH++ntfwxL+dE/bOQ/cQ82t8oHhS7f35tgJueRp234TlVTiGcaed2Orqai1cuFBTp07VtGnTtGbNGnV0dGjRokWSpAULFmj48OGqra2VJM2ePVurV6/WpZdeGpkGX7FihWbPnh1J2mcT92T97LPPxvslAQDoUcjyKBTDNLid2Hnz5mn//v1auXKlWltbNXnyZG3atCmy6Gz37t1RI+l7771XHo9H9957rz7//HMNGzZMs2fP1r/927/1uU2eDQ4AgKGqqipVVVX1+LWGhoaof6ekpKimpkY1NTW22yNZAwBcK14LzJyOZA0AcC0rxqpblksKeZCsAQCuFZJHIZvFOE7Fu4E73lIAAJDEGFkDAFwrbMV23zls75OrA45kDQBwrXCM96xjiR1I7uglAABJjJE1AMC1wvIoHMMisVhiBxLJGgDgWol4glkiMA0OAIDDJfXI2puRbisu3NFhHPPFJWcvvfZ1qV8Yhyg0yLw4iZ3iH5LUdcj8/HUP7TaOydhnXlzDG7S3xDOYbf4uO63dvK2QjUvvRJ5531LNL1VJUtcg8xg7hV18AfPxQijD/Hx7gzZHT2nm31P3NVOMY1LqG41jrC7z36VzUbIsMEvqZA0AcLewYnzcqEvuWbvjLQUAAEmMkTUAwLWsGFeDWy4ZWZOsAQCuRdUtAAAcLlkWmLmjlwAAJDFG1gAA12IaHAAAh0uWx40yDQ4AgMMxsgYAuBbT4AAAOFyyJGumwQEAcDhG1gAA10qWkXVSJ2s71bPsOnq++QXhCZlXFwp3mFeoyh/ZbhwjSW1tmeZBmV3GIb6geTPdGfZ+AVNOmJ9zO5W6LPPiaLLz7AY71bPstmV5B6YalpUaMo7xnLBxwiWp0/xEHB5r3lZevXGIPKn2/nxbAfPz52TJkqyZBgcAwOGSemQNAHA3S7F9Vtp8PigxSNYAANdKlmlwkjUAwLWSJVlzzxoAAIdjZA0AcK1kGVmTrAEArpUsyZppcAAAHI6RNQDAtSzLIyuG0XEssQOJZA0AcC3qWQMAAEdgZA0AcK1kWWBGsh4gJ8aYV6Pwt6QZx3jSB+4h/alHzS/yrhzzdrrTzWPs6vLZKbhi3o6dGDvFNey0Y7ut8AD90Us1f0Ckx+YzJe18T4fHmTeWZxwhWYGAjahzT7Lcs2YaHAAAh2NkDQBwLabBAQBwuGSZBidZAwBcy4pxZO2WZM09awAAHI6RNQDAtSxJls3V/qfi3YBkDQBwrbA88vAEMwAAkGiMrAEArsVqcAAAHC5seeRJgs9ZMw0OAIDDMbIGALiWZcW4Gtwly8FJ1gOksOgL45jDnxYYx6SkdxnH2JXSYT59FLRRGMETNg6xVYjCbpzdYhmQLJ+NIJ/5X9ewzb90nqD59Wrre4JtyXLPmmlwAAAcjpE1AMC1kmVkTbIGALgWq8F78eabb2r27NkqLi6Wx+PRSy+9FPV1y7K0cuVKFRUVKSMjQ+Xl5fr444/j1V8AACJOLTCLZXMD42Td0dGhSZMmqa6ursevr1q1So899pjWrl2rd955R4MGDVJFRYU6Oztj7iwAAMnIeBp81qxZmjVrVo9fsyxLa9as0b333qsf/OAHkqQ//OEPKigo0EsvvaTrr7/+tJhAIKBAIBD5d3t7u2mXAABJ6uToOJZ71nHsTD+K62rwXbt2qbW1VeXl5ZF9OTk5Ki0t1datW3uMqa2tVU5OTmQrKSmJZ5cAAOewUwvMYtncIK7JurW1VZJUUBD9+eCCgoLI175u+fLlOnLkSGRraWmJZ5cAAHC9hK8G9/v98vv9ie4GAMCFLMVWk9ols+DxHVkXFhZKktra2qL2t7W1Rb4GAEC8MA1uw+jRo1VYWKj6+vrIvvb2dr3zzjsqKyuLZ1MAACQN42nwY8eOaceOHZF/79q1S01NTcrNzdX555+vpUuX6qGHHtKFF16o0aNHa8WKFSouLtacOXPi2W8AAJJmHtw4Wb/33nu6+uqrI/+urq6WJC1cuFDr16/XXXfdpY6ODt1yyy06fPiwrrjiCm3atEnp6enx67ULtX6WaxwzKHD2Y77O8g7clZdy3EZQyEYhDwpluIONn61loyiHx8Y1Hs6wUQ1Gku+Y+eRjdzYX7ICKdSrbZmxdXZ0eeeQRtba2atKkSfrVr36ladOm9Xr84cOH9bOf/UwvvPCCDh06pJEjR2rNmjW69tpr+9SecbKePn26rDN8MM3j8eiBBx7QAw88YPrSAAAYSUSJzI0bN6q6ulpr165VaWmp1qxZo4qKCjU3Nys/P/+044PBoP75n/9Z+fn5+uMf/6jhw4fr73//u4YMGdLnNhO+GhwAADdZvXq1lixZokWLFkmS1q5dq1dffVXr1q3TPffcc9rx69at06FDh/T2228rNTVVkjRq1CijNimRCQBwrXitBm9vb4/avvpkza8KBoNqbGyMeviX1+tVeXl5rw//+s///E+VlZWpsrJSBQUFGj9+vB5++GGFQn2/ZUKyBgC4l+WJfZNUUlIS9TTN2traHps7cOCAQqGQ0cO/PvnkE/3xj39UKBTSa6+9phUrVujRRx/VQw891Odvk2lwAEDSa2lpUXZ2duTf8XxYVzgcVn5+vn7zm9/I5/NpypQp+vzzz/XII4+opqamT69BsgYAuFa8FphlZ2dHJeve5OXlyefzGT38q6ioSKmpqfL5fJF93/zmN9Xa2qpgMKi0tLSztss0OADAvaw4bAbS0tI0ZcqUqId/hcNh1dfX9/rwr8svv1w7duxQOPzlRwg/+ugjFRUV9SlRSyRrAACMVFdX68knn9Tvf/97/e1vf9Ntt92mjo6OyOrwBQsWaPny5ZHjb7vtNh06dEh33HGHPvroI7366qt6+OGHVVlZ2ec2mQYHALhWrM/3thM7b9487d+/XytXrlRra6smT56sTZs2RRad7d69W17vl2PhkpISvf7661q2bJkmTpyo4cOH64477tDdd9/d5zZJ1gAAd0vAI0OrqqpUVVXV49caGhpO21dWVqZt27bZbo9pcAAAHI6RNQDAtRIxDZ4IJGsAgHtRdQu98vrOfszX2agu5P/CPKaz27xvofAA3g2xcR4sG6c7ZPN5Bj4blc7s8A5QYaaQzWJ3ds65N2g+QunKsnE9HLfRuUx7Jzy11byt7qHm35NvqHlVvtDBQ8Yx5ybPP7ZY4p2Pe9YAADgcI2sAgHsxDQ4AgMMlSbJmGhwAAIdjZA0AcK+vlLm0He8CJGsAgGvFq+qW0zENDgCAwzGyBgC4V5IsMCNZAwDcK0nuWTMNDgCAwzGyBgC4lsc6ucUS7wYkawCAe3HPGr3xjR05IO0M2mdefOBQR6pxTGemvcsgaF57QJ6j5m1ZNm7W2ClEIUkeG/Uewuan3Ba735Ottmyc89Sj5vf+Oku6jWMyPzE/4b7SL4xjJKn7kzTjGG+6+ffUdbH53xTv/6aQhyTuWQMAAGdgZA0AcC+mwQEAcLgkSdZMgwMA4HCMrAEA7pUkI2uSNQDAvVgNDgAAnICRNQDAtXiCGQAATpck96yZBgcAwOFI1gAAOBzT4AAA1/IoxnvWcetJ/yJZ23DskjzjGG9ql3GMp9t84iOtzfxHeiyQbRwjSRpqXvUi9bD592SngIXd4hpeG4U8urLsteVkXvPLdcAKmvgPm/9lDoTsTSLaKexiR/vodOOYIf+7HzriRnx0CwAAOAEjawCAeyXJanCSNQDAvZIkWTMNDgCAwzGyBgC4Fk8wAwDA6ZgGBwAATsDIGgDgXkkysiZZAwBcK1nuWTMNDgCAwzGyBgC4V5I8bpRkDQBwL+5ZozdfXGB+2sKd5ldEyG/+js9/yM67RHt3Q7pGBI1jUj73G8eEzENsF2DwhMx/TuFU83Oectw4RJbDb1rZKbiiLvNz5+u00Y5NA1WcpPM8d4zunIh71gAAwBEYWQMA3ItpcAAAHC7GaXC3JGvjafA333xTs2fPVnFxsTwej1566aWor998883yeDxR28yZM+PVXwAAko5xsu7o6NCkSZNUV1fX6zEzZ87U3r17I9szzzwTUycBAOiRFYfNBYynwWfNmqVZs2ad8Ri/36/CwsI+vV4gEFAgEIj8u7293bRLAIBklST3rPtlNXhDQ4Py8/N10UUX6bbbbtPBgwd7Pba2tlY5OTmRraSkpD+6BACAa8U9Wc+cOVN/+MMfVF9fr1/84hfasmWLZs2apVCo5w++Ll++XEeOHIlsLS0t8e4SAOAcdepz1rFsbhD31eDXX3995P8nTJigiRMnauzYsWpoaNA111xz2vF+v19+v42nXgAAkCT6/aEoY8aMUV5ennbs2NHfTQEAcE7q989Zf/bZZzp48KCKior6uykAQLJJkgVmxsn62LFjUaPkXbt2qampSbm5ucrNzdX999+vuXPnqrCwUDt37tRdd92lCy64QBUVFXHtOAAAyfJscONk/d577+nqq6+O/Lu6ulqStHDhQj3xxBP64IMP9Pvf/16HDx9WcXGxZsyYoQcffPCcui/dnWke4zluXuXgeL75w/3T2s2vvECucYgkKSW9yzjGEza/DgJDw8YxmXvs3eEJpQ1MQYWUEzYKu9joW1e6cYgke0VDvOaXg60bcf528+vhi4C9ihxp5k3JCpl/U3b+puArXJJwY2GcrKdPny7L6v3MvP766zF1CAAAROPZ4AAA9+KeNQAAzpYs96ypZw0AgMMxsgYAuBfT4AAAOBvT4AAAwBFI1gAA90pQPeu6ujqNGjVK6enpKi0t1bvvvtunuGeffVYej0dz5swxao9kDQBwrwQk640bN6q6ulo1NTV6//33NWnSJFVUVGjfvn1njPv0009155136sorrzRuk2QNAEh67e3tUVsgEOj12NWrV2vJkiVatGiRLr74Yq1du1aZmZlat25drzGhUEg33nij7r//fo0ZM8a4fyRrAIBrxauedUlJiXJyciJbbW1tj+0Fg0E1NjaqvLw8ss/r9aq8vFxbt27ttZ8PPPCA8vPztXjxYlvfJ6vBAQDuFaePbrW0tCg7Ozuyu7d6FgcOHFAoFFJBQUHU/oKCAn344Yc9xrz11lv63e9+p6amJtvdJFkDANwrTsk6Ozs7KlnHy9GjR3XTTTfpySefVF5enu3XIVnb0J1pfmV4g+YVkyyfeUyKjYpEHhtVgiSpu8u8kpidak6ekHmMrQpQA2igqnvZOd8DymejSly2jesuZO98h20U67K6zE96INclH/aF8vLy5PP51NbWFrW/ra1NhYWFpx2/c+dOffrpp5o9e3ZkXzh88u90SkqKmpubNXbs2LO26/RfZQAAehWve9Z9lZaWpilTpqi+vj6yLxwOq76+XmVlZacdP27cOP33f/+3mpqaItv3v/99XX311WpqalJJSUmf2mVkDQBwrwQ8brS6uloLFy7U1KlTNW3aNK1Zs0YdHR1atGiRJGnBggUaPny4amtrlZ6ervHjx0fFDxkyRJJO238mJGsAAAzMmzdP+/fv18qVK9Xa2qrJkydr06ZNkUVnu3fvltcb34lrkjUAwLUS9WzwqqoqVVVV9fi1hoaGM8auX7/euD2SNQDAvZKk6hYLzAAAcDhG1gAA90qSkTXJGgDgWp5/bLHEuwHT4AAAOBwjawCAezENDgCAsyXqo1sDjWQNAHAvRtboTfcQ88oSaQfMiw90DTIOUdZn5oU87BQMsSuUbh5jpZn/NvmC5u0MJMv8cnB0O5LN4ik2CmwEs81jwjaKzkhS2Ma15wmYLwWybBQ0QXIhWQMA3C0J3uuQrAEArpUs96z56BYAAA7HyBoA4F4sMAMAwNmYBgcAAI7AyBoA4F5MgwMA4GxMgwMAAEdgZA0AcC+mwQEAcDiSNQAAzpYs96xJ1nakmRfL8ITMT3VXlvlVFLZRlCPkNw6RJFmhAVryYKPYg13dNgqNhPw2fk6p5t+Tx7x+jG32CkvY+DnZaCecat6MgvauVcvOpWfjeg1nmv9NQXIhWQMA3ItpcAAAnM1jWfJY9jNuLLEDiY9uAQDgcIysAQDuxTQ4AADOliyrwZkGBwDA4RhZAwDci2lwAACcjWlwAADgCIysAQDuxTQ4AADOlizT4CRrAIB7MbI+96UML7YXaONB/b5OG82km7eTsS9oHOML2KheISkl07yt7sw045j0/eZLK9La7f0GprXbiTL/OQ3aa6MYjI1aDx1F9palhPzm35O3y05DA9NOymGfeZAkb7d5THeqjZ9t+gBWaYErJXWyBgC4n1umsmNBsgYAuJdlndxiiXcBProFAIDDGSXr2tpaXXbZZcrKylJ+fr7mzJmj5ubmqGM6OztVWVmpoUOHavDgwZo7d67a2tri2mkAAKQvV4PHsrmBUbLesmWLKisrtW3bNm3evFldXV2aMWOGOjo6IscsW7ZMf/rTn/T8889ry5Yt2rNnj6677rq4dxwAgMhq8Fg2FzC6Z71p06aof69fv175+flqbGzUVVddpSNHjuh3v/udNmzYoH/6p3+SJD311FP65je/qW3btunb3/72aa8ZCAQUCAQi/25vt7UcFwCAc1ZM96yPHDkiScrNzZUkNTY2qqurS+Xl5ZFjxo0bp/PPP19bt27t8TVqa2uVk5MT2UpKSmLpEgAgiXjCsW9uYDtZh8NhLV26VJdffrnGjx8vSWptbVVaWpqGDBkSdWxBQYFaW1t7fJ3ly5fryJEjka2lpcVulwAAyYZp8DOrrKzU9u3b9dZbb8XUAb/fL7/fH9NrAABwLrM1sq6qqtIrr7yiN954QyNGjIjsLywsVDAY1OHDh6OOb2trU2FhYUwdBQDg61gN3gPLslRVVaUXX3xRf/nLXzR69Oior0+ZMkWpqamqr6+P7Gtubtbu3btVVlYWnx4DAHDKqYeixLK5gNE0eGVlpTZs2KCXX35ZWVlZkfvQOTk5ysjIUE5OjhYvXqzq6mrl5uYqOztbt99+u8rKynpcCQ4AQCyoutWDJ554QpI0ffr0qP1PPfWUbr75ZknSL3/5S3m9Xs2dO1eBQEAVFRV6/PHH49LZeLOyB9mK89h4UL8dXVnm7aS2HjGOCRbbK3KQlWZe5SCYYf49daaZF3uwUwRFkiwbp6Irz7yyxLExNgpYdJrftbJ89q5Vy8Y1ntJufvK8x82/p+5M4xClHLd3PXRlmf8l93SZf08en50qKEgmRsna6sN0QXp6uurq6lRXV2e7UwAA9AklMgEAcLZkmQankAcAAA7HyBoA4F5JUiKTZA0AcC2mwQEAgCMwsgYAuBerwQEAcDamwQEAgCMwsgYAuFfYOrnFEu8CJGsAgHtxzxoAAGfzKMZ71nHrSf/injUAAA6X1CPrYEGWrTiPjUpGdqo5eYM23vOlmDc0rMC8Upck5WYcN45pKTJ/f+izcb47jqYbx0iSx2f+Ft0bsvFzstG99IKgcYydcydJxdntxjGHTpiXw0pPMa/c1tlt/mfri//OM46RJMvO9WDj99abGjKPGWSvamC4o8NWnGPxBDMAAJyNj24BAIAe1dXVadSoUUpPT1dpaanefffdXo998skndeWVV+q8887Teeedp/Ly8jMe3xOSNQDAvaw4bIY2btyo6upq1dTU6P3339ekSZNUUVGhffv29Xh8Q0OD5s+frzfeeENbt25VSUmJZsyYoc8//7zPbZKsAQCu5bGsmDdJam9vj9oCgUCvba5evVpLlizRokWLdPHFF2vt2rXKzMzUunXrejz+6aef1o9//GNNnjxZ48aN029/+1uFw2HV19f3+fskWQMAkl5JSYlycnIiW21tbY/HBYNBNTY2qry8PLLP6/WqvLxcW7du7VNbx48fV1dXl3Jzc/vcPxaYAQDcK/yPLZZ4SS0tLcrOzo7s9vv9PR5+4MABhUIhFRQURO0vKCjQhx9+2Kcm7777bhUXF0cl/LMhWQMAXOurU9l24yUpOzs7Kln3l5///Od69tln1dDQoPT0vn+Gk2QNAEAf5eXlyefzqa2tLWp/W1ubCgsLzxj77//+7/r5z3+uP//5z5o4caJRu9yzBgC41wCvBk9LS9OUKVOiFoedWixWVlbWa9yqVav04IMPatOmTZo6dapZo2JkDQBwswQ8way6uloLFy7U1KlTNW3aNK1Zs0YdHR1atGiRJGnBggUaPnx4ZJHaL37xC61cuVIbNmzQqFGj1NraKkkaPHiwBg8e3Kc2SdYAANdKxBPM5s2bp/3792vlypVqbW3V5MmTtWnTpsiis927d8vr/XLi+oknnlAwGNS//Mu/RL1OTU2N7rvvvj61SbIGAMBQVVWVqqqqevxaQ0ND1L8//fTTmNtL6mQd8tu9ZW/+0H07vOY1DnTsovOMY877ntlj706x82Z2hPr+xB4kjp2frfmVZ0+GjZhj9w6z1VbnMPMz4ev9WRq98nptFAzJ6/tndL+KQh49xLtAUidrAIC7ecInt1ji3YDV4AAAOBwjawCAezENDgCAw9msnBUV7wJMgwMA4HCMrAEArhWvZ4M7HckaAOBeSXLPmmlwAAAcjpE1AMC9LMVWz9odA2uSNQDAvbhnDQCA01mK8Z513HrSr7hnDQCAwyX1yLrtsjRbcemZR4xjugalG8eE/OZv+cI+j3EMcK7rHmRv+GT5zW+Gdtv4HRyRc8w45uilRcYxkpTx9xZbcY6VJKvBkzpZAwBcLiwpljEKhTwAAEA8MLIGALgWq8EBAHC6JLlnzTQ4AAAOx8gaAOBeSTKyJlkDANwrSZI10+AAADgcI2sAgHslyeesSdYAANfio1sAADgd96wBAIATJPXIuvOCgK24DBsxXTkhW22ZCmT7jGMG2W3Ma96WwgNzHoCv6s60N3ry554wjukKmP9ZPRYwLyrkO8/G75/s/f1ytLAleWIYHYfdMbJO6mQNAHA5psEBAIATMLIGALhYjCNrnYMj69raWl122WXKyspSfn6+5syZo+bm5qhjpk+fLo/HE7Xdeuutce00AACSvpwGj2VzAaNkvWXLFlVWVmrbtm3avHmzurq6NGPGDHV0dEQdt2TJEu3duzeyrVq1Kq6dBgAgmRhNg2/atCnq3+vXr1d+fr4aGxt11VVXRfZnZmaqsLCwT68ZCAQUCHy5Kru9vd2kSwCAZBa2FNNUtktWg8e0wOzIkSOSpNzc3Kj9Tz/9tPLy8jR+/HgtX75cx48f7/U1amtrlZOTE9lKSkpi6RIAIJlY4dg3F7C9wCwcDmvp0qW6/PLLNX78+Mj+G264QSNHjlRxcbE++OAD3X333WpubtYLL7zQ4+ssX75c1dXVkX+3t7eTsAEA+ArbybqyslLbt2/XW2+9FbX/lltuifz/hAkTVFRUpGuuuUY7d+7U2LFjT3sdv98vv99vtxsAgGTG56x7V1VVpVdeeUVvvPGGRowYccZjS0tLJUk7duyw0xQAAL0LW7FvLmA0srYsS7fffrtefPFFNTQ0aPTo0WeNaWpqkiQVFRXZ6iAAAL1KkpG1UbKurKzUhg0b9PLLLysrK0utra2SpJycHGVkZGjnzp3asGGDrr32Wg0dOlQffPCBli1bpquuukoTJ07sl28AAIBznVGyfuKJJySdfPDJVz311FO6+eablZaWpj//+c9as2aNOjo6VFJSorlz5+ree++NW4cBAIiwFOPIOm496VfG0+BnUlJSoi1btsTUoYE0ouiQrbjDJ9LNg9JtfDyg09mPbvekmq9PtAJU3cKXPDYWl1oB82p53qDHOEaSfD7z39twqvk1fl6meXWvz2cdM46RpNynbIU5V5JMgzs7GwAAAAp5AABcLByWFMODTcLn+ENRAABIOKbBAQCAEzCyBgC4V5KMrEnWAAD3ouoWAABwAkbWAADXsqywrBjKXMYSO5BI1gAA97JiLMbBPWsAAPqZFeM9a5cka+5ZAwDgcIysAQDuFQ5LnhjuO3PP2vk8vxpmK657svlp8+WYT7WEBpkXBLB8xiFAwnhS7BSDMS/kYfnsTXUe3z/IOCbjM/PvaV/nYOOYrIPumL7td0yDAwAAJ0jqkTUAwN2scFhWDNPgfHQLAID+xjQ4AABwAkbWAAD3CluS59wfWZOsAQDuZVmSYvnoljuSNdPgAAA4HCNrAIBrWWFLVgzT4JZLRtYkawCAe1lhxTYN7o6PbjENDgBwLStsxbzZUVdXp1GjRik9PV2lpaV69913z3j8888/r3Hjxik9PV0TJkzQa6+9ZtQeyRoAAAMbN25UdXW1ampq9P7772vSpEmqqKjQvn37ejz+7bff1vz587V48WL99a9/1Zw5czRnzhxt3769z206bhr81P2DbnXF9Dn3vuju6rQVFwqYn7Zwp/k3E/aaPxs8FDR/OHi31WUcI0key/y9nmWzLZybvFbQOCZs4xoKd9r7XQ/beDKWnb8PMn/cuUJBe38g7f6+G7Whk20MxP3gbisQ01T2qb62t7dH7ff7/fL7/T3GrF69WkuWLNGiRYskSWvXrtWrr76qdevW6Z577jnt+P/4j//QzJkz9ZOf/ESS9OCDD2rz5s369a9/rbVr1/ato5bDtLS0nHocDRsbGxubi7eWlpZ+yxUnTpywCgsL49LPwYMHn7avpqamx3YDgYDl8/msF198MWr/ggULrO9///s9xpSUlFi//OUvo/atXLnSmjhxYp+/X8eNrIuLi9XS0qKsrCx5PJ6or7W3t6ukpEQtLS3Kzs5OUA8Tj/NwEufhJM7DSZyHk5xwHizL0tGjR1VcXNxvbaSnp2vXrl0KBs1nZ77OsqzT8k1vo+oDBw4oFAqpoKAgan9BQYE+/PDDHmNaW1t7PL61tbXPfXRcsvZ6vRoxYsQZj8nOzk7qX8ZTOA8ncR5O4jycxHk4KdHnIScnp9/bSE9PV3p6er+34wQsMAMAoI/y8vLk8/nU1tYWtb+trU2FhYU9xhQWFhod3xOSNQAAfZSWlqYpU6aovr4+si8cDqu+vl5lZWU9xpSVlUUdL0mbN2/u9fieOG4a/Ez8fr9qamp6vZeQLDgPJ3EeTuI8nMR5OInz0P+qq6u1cOFCTZ06VdOmTdOaNWvU0dERWR2+YMECDR8+XLW1tZKkO+64Q9/97nf16KOP6nvf+56effZZvffee/rNb37T5zY9luWSZ60BAOAQv/71r/XII4+otbVVkydP1mOPPabS0lJJ0vTp0zVq1CitX78+cvzzzz+ve++9V59++qkuvPBCrVq1Stdee22f2yNZAwDgcNyzBgDA4UjWAAA4HMkaAACHI1kDAOBwrknWpuXIzkX33XefPB5P1DZu3LhEd6vfvfnmm5o9e7aKi4vl8Xj00ksvRX3dsiytXLlSRUVFysjIUHl5uT7++OPEdLYfne083HzzzaddHzNnzkxMZ/tJbW2tLrvsMmVlZSk/P19z5sxRc3Nz1DGdnZ2qrKzU0KFDNXjwYM2dO/e0B1K4XV/Ow/Tp00+7Hm699dYE9RixckWyNi1Hdi675JJLtHfv3sj21ltvJbpL/a6jo0OTJk1SXV1dj19ftWqVHnvsMa1du1bvvPOOBg0apIqKCnXarLTkVGc7D5I0c+bMqOvjmWeeGcAe9r8tW7aosrJS27Zt0+bNm9XV1aUZM2aoo6MjcsyyZcv0pz/9Sc8//7y2bNmiPXv26Lrrrktgr+OvL+dBkpYsWRJ1PaxatSpBPUbM+lzyI4GmTZtmVVZWRv4dCoWs4uJiq7a2NoG9Gng1NTXWpEmTEt2NhJIUVe0mHA5bhYWF1iOPPBLZd/jwYcvv91vPPPNMAno4ML5+HizLshYuXGj94Ac/SEh/EmXfvn2WJGvLli2WZZ382aemplrPP/985Ji//e1vliRr69atiepmv/v6ebAsy/rud79r3XHHHYnrFOLK8SPrYDCoxsZGlZeXR/Z5vV6Vl5dr69atCexZYnz88ccqLi7WmDFjdOONN2r37t2J7lJC7dq1S62trVHXR05OjkpLS5Py+mhoaFB+fr4uuugi3XbbbTp48GCiu9Svjhw5IknKzc2VJDU2Nqqrqyvqehg3bpzOP//8c/p6+Pp5OOXpp59WXl6exo8fr+XLl+v48eOJ6B7iwPGPG7VTjuxcVVpaqvXr1+uiiy7S3r17df/99+vKK6/U9u3blZWVlejuJcSpEnOxlp87F8ycOVPXXXedRo8erZ07d+qnP/2pZs2apa1bt8rn8yW6e3EXDoe1dOlSXX755Ro/frykk9dDWlqahgwZEnXsuXw99HQeJOmGG27QyJEjVVxcrA8++EB33323mpub9cILLySwt7DL8ckaX5o1a1bk/ydOnKjS0lKNHDlSzz33nBYvXpzAnsEJrr/++sj/T5gwQRMnTtTYsWPV0NCga665JoE96x+VlZXavn17UqzbOJPezsMtt9wS+f8JEyaoqKhI11xzjXbu3KmxY8cOdDcRI8dPg9spR5YshgwZom984xvasWNHoruSMKeuAa6P040ZM0Z5eXnn5PVRVVWlV155RW+88YZGjBgR2V9YWKhgMKjDhw9HHX+uXg+9nYeenHpu9bl4PSQDxydrO+XIksWxY8e0c+dOFRUVJborCTN69GgVFhZGXR/t7e165513kv76+Oyzz3Tw4MFz6vqwLEtVVVV68cUX9Ze//EWjR4+O+vqUKVOUmpoadT00Nzdr9+7d59T1cLbz0JOmpiZJOqeuh2Tiimnws5UjSxZ33nmnZs+erZEjR2rPnj2qqamRz+fT/PnzE921fnXs2LGo0cCuXbvU1NSk3NxcnX/++Vq6dKkeeughXXjhhRo9erRWrFih4uJizZkzJ3Gd7gdnOg+5ubm6//77NXfuXBUWFmrnzp266667dMEFF6iioiKBvY6vyspKbdiwQS+//LKysrIi96FzcnKUkZGhnJwcLV68WNXV1crNzVV2drZuv/12lZWV6dvf/naCex8/ZzsPO3fu1IYNG3Tttddq6NCh+uCDD7Rs2TJdddVVmjhxYoJ7D1sSvRy9r371q19Z559/vpWWlmZNmzbN2rZtW6K7NODmzZtnFRUVWWlpadbw4cOtefPmWTt27Eh0t/rdG2+8YUk6bVu4cKFlWSc/vrVixQqroKDA8vv91jXXXGM1NzcnttP94Ezn4fjx49aMGTOsYcOGWampqdbIkSOtJUuWWK2trYnudlz19P1Lsp566qnIMSdOnLB+/OMfW+edd56VmZlp/fCHP7T27t2buE73g7Odh927d1tXXXWVlZuba/n9fuuCCy6wfvKTn1hHjhxJbMdhGyUyAQBwOMffswYAINmRrAEAcDiSNQAADkeyBgDA4UjWAAA4HMkaAACHI1kDAOBwJGsAAByOZA0AgMORrAEAcDiSNQAADvf/AUSCbeqZDnt8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Pullover\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "print(\"Class:\", class_names[label[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过如下方式构建其PyTorch模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MLP, self).__init__()\n",
    "    self.linear0 = nn.Linear(784, 128, bias=True)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.linear1 = nn.Linear(128, 10, bias=True)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.linear0(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.linear1(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "mlp_model = MLP()\n",
    "\n",
    "mlp_params = pkl.load(open(\"fasionmnist_mlp_params.pkl\", \"rb\"))\n",
    "mlp_model.linear0.weight.data = torch.from_numpy(mlp_params[\"w0\"])\n",
    "mlp_model.linear0.bias.data = torch.from_numpy(mlp_params[\"b0\"])\n",
    "mlp_model.linear1.weight.data = torch.from_numpy(mlp_params[\"w1\"])\n",
    "mlp_model.linear1.bias.data = torch.from_numpy(mlp_params[\"b1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Prediction: Pullover\n"
     ]
    }
   ],
   "source": [
    "torch_res = mlp_model(torch.from_numpy(img.reshape(1, 784)))\n",
    "\n",
    "pred_kind = np.argmax(torch_res.detach().numpy(), axis=1)\n",
    "print(\"Torch Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们尝试通过为相应的`nn.Module`定义映射函数来从FX转换。 在这里，我们**重用了来自TVM TOPI(TVM operator inventory)的预定义TE库，而不是定义我们自己的张量表达式**\n",
    "+ `topi.nn.dense(x, w)`执行转置矩阵乘法`x @ w.T`\n",
    "+ `topi.add`执行广播加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">te_relu</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;te_relu&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "                i0_1, i1_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[i0_1, i1_1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[i0_1, i1_1])\n",
       "                relu[i0_1, i1_1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[i0_1, i1_1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">add1</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[<span style=\"color: #008000\">10</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>], T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;add1&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                ax0, ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[ax0, ax1], rxplaceholder_1[ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[ax0, ax1])\n",
       "                T_add[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_1[ax1]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">dense1</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], T_matmul_NT: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;dense1&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>, <span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>]})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NT&quot;</span>):\n",
       "                i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, i2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[i, k], rxplaceholder_1[j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NT[i, j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NT[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NT[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NT[i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[j, k]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">dense</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], T_matmul_NT: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;dense&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>, <span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>]})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">784</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NT&quot;</span>):\n",
       "                i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, i2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[i, k], rxplaceholder_1[j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NT[i, j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NT[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NT[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NT[i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[j, k]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">add</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[<span style=\"color: #008000\">128</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>], T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;add&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                ax0, ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[ax0, ax1], rxplaceholder_1[ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[ax0, ax1])\n",
       "                T_add[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_1[ax1]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">main</span>(x: Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #008000\">2</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(dense, (x, meta[relay<span style=\"color: #AA22FF; font-weight: bold\">.</span>Constant][<span style=\"color: #008000\">0</span>]), (<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(add, (lv, meta[relay<span style=\"color: #AA22FF; font-weight: bold\">.</span>Constant][<span style=\"color: #008000\">1</span>]), (<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_relu, (lv1,), (<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(dense1, (lv2, meta[relay<span style=\"color: #AA22FF; font-weight: bold\">.</span>Constant][<span style=\"color: #008000\">2</span>]), (<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv4 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(add1, (lv3, meta[relay<span style=\"color: #AA22FF; font-weight: bold\">.</span>Constant][<span style=\"color: #008000\">3</span>]), (<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            gv: Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv4\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> lv4\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tvm import topi\n",
    "\n",
    "\n",
    "def map_nn_linear(bb, node_map, node, nn_mod):\n",
    "    x = node_map[node.args[0]]\n",
    "    w = map_param(nn_mod.weight)\n",
    "    if nn_mod.bias is not None:\n",
    "        b = map_param(nn_mod.bias)\n",
    "    y = bb.emit_te(topi.nn.dense, x, w)\n",
    "    return bb.emit_te(topi.add, y, b)\n",
    "\n",
    "def map_nn_relu(bb, node_map, node, nn_mod):\n",
    "    return map_relu(bb, node_map, node)\n",
    "\n",
    "\n",
    "MLPModule = from_fx(\n",
    "    fx.symbolic_trace(mlp_model),\n",
    "    input_shapes = [(1, 784)],\n",
    "    call_function_map={\n",
    "    },\n",
    "    call_module_map={\n",
    "        torch.nn.Linear: map_nn_linear,\n",
    "        torch.nn.ReLU: map_nn_relu,\n",
    "    },\n",
    ")\n",
    "\n",
    "MLPModule.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModule Prediction: Pullover\n"
     ]
    }
   ],
   "source": [
    "ex = relax.vm.build(MLPModule, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "data_nd = tvm.nd.array(img.reshape(1, 784))\n",
    "\n",
    "nd_res = vm[\"main\"](data_nd)\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MLPModule Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在大多数机器学习框架中，有时先转换为更高一级的内置的原始算子会更有帮助。下面的代码块给出了一个例子来做到这一点，下面展示了我们使用哪些内置的算子将模型导入为IRModule后的结果。这些内置算子是比TensorIR函数更高级别的抽象。我们可以有不同的机会将这些原始算子进一步转换为库函数或TensorIR函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">main</span>(x: Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #008000\">2</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> relax<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>dense(x, meta[relay<span style=\"color: #AA22FF; font-weight: bold\">.</span>Constant][<span style=\"color: #008000\">0</span>])\n",
       "            lv1: Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> relax<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv, meta[relay<span style=\"color: #AA22FF; font-weight: bold\">.</span>Constant][<span style=\"color: #008000\">1</span>])\n",
       "            lv2: Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> relax<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu(lv1)\n",
       "            lv3: Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> relax<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>dense(lv2, meta[relay<span style=\"color: #AA22FF; font-weight: bold\">.</span>Constant][<span style=\"color: #008000\">2</span>])\n",
       "            lv4: Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> relax<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv3, meta[relay<span style=\"color: #AA22FF; font-weight: bold\">.</span>Constant][<span style=\"color: #008000\">3</span>])\n",
       "            gv: Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv4\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> lv4\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_nn_relu_op(bb, node_map, node, nn_mod):\n",
    "    A = node_map[node.args[0]]\n",
    "    return bb.emit(relax.op.relu(A))\n",
    "\n",
    "def map_nn_linear_op(bb, node_map, node, nn_mod):\n",
    "    x = node_map[node.args[0]]\n",
    "    w = map_param(nn_mod.weight)\n",
    "    if nn_mod.bias is not None:\n",
    "        b = map_param(nn_mod.bias)\n",
    "    y = bb.emit(relax.op.dense(x, w))\n",
    "    return bb.emit(relax.op.add(y, b))\n",
    "\n",
    "MLPModuleHighLevel = from_fx(\n",
    "    fx.symbolic_trace(mlp_model),\n",
    "    input_shapes = [(1, 784)],\n",
    "    call_function_map={\n",
    "    },\n",
    "    call_module_map={\n",
    "        torch.nn.Linear: map_nn_linear_op,\n",
    "        torch.nn.ReLU: map_nn_relu_op,\n",
    "    },\n",
    ")\n",
    "\n",
    "MLPModuleHighLevel.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba081e9997e81855924de74792aadcd790df3c3d18fa78a445749b56473709c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
